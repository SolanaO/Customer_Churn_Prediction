{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f49f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary libraries and packages\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from wordcloud import (\n",
    "    WordCloud,\n",
    "    ImageColorGenerator,\n",
    "    )\n",
    "import stylecloud\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    IntegerType, \n",
    "    DateType, \n",
    "    TimestampType,\n",
    "    )\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    min as Fmin, max as Fmax, \n",
    "    sum as Fsum, round as Fround, \n",
    "    col, desc, asc,\n",
    "    count, countDistinct, \n",
    "    when, lit,  \n",
    "    isnull, isnan,\n",
    "    from_unixtime, dayofmonth, month, hour, date_format,\n",
    "    lag, lead,\n",
    "    first, last, split,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16aad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a Spark session using the SparkSession APIs\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder \n",
    "        .appName(\"ExplorePySpark\")\n",
    "        .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f08a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create Spark context\n",
    "\n",
    "from pyspark import SQLContext,SparkConf,SparkContext,HiveContext\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DateType\n",
    "import pyspark.sql.functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a774f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_data = \\\n",
    "[('Alex','2018-10-10','Paint',80),('Alex','2018-04-02','Ladder',20),('Alex','2018-06-22','Stool',20),\\\n",
    "('Alex','2018-12-09','Vacuum',40),('Alex','2018-07-12','Bucket',5),('Alex','2018-02-18','Gloves',5),\\\n",
    "('Alex','2018-03-03','Brushes',30),('Alex','2018-09-26','Sandpaper',10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8f2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(shopping_data, ['name','date','product','price'])\\\n",
    "                .withColumn('date',F.col('date').cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444a8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- price: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357c7288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+\n",
      "|name|      date|  product|price|\n",
      "+----+----------+---------+-----+\n",
      "|Alex|2018-10-10|    Paint|   80|\n",
      "|Alex|2018-04-02|   Ladder|   20|\n",
      "|Alex|2018-06-22|    Stool|   20|\n",
      "|Alex|2018-12-09|   Vacuum|   40|\n",
      "|Alex|2018-07-12|   Bucket|    5|\n",
      "|Alex|2018-02-18|   Gloves|    5|\n",
      "|Alex|2018-03-03|  Brushes|   30|\n",
      "|Alex|2018-09-26|Sandpaper|   10|\n",
      "+----+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbb29a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = Window.partitionBy('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a38ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Window().partitionBy(\"name\").rowsBetween(Window.unboundedPreceding,\n",
    "                                              Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb12c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+\n",
      "|name|      date|  product|price|price_rank|\n",
      "+----+----------+---------+-----+----------+\n",
      "|Alex|2018-10-10|    Paint|   80|         1|\n",
      "|Alex|2018-12-09|   Vacuum|   40|         2|\n",
      "|Alex|2018-03-03|  Brushes|   30|         3|\n",
      "|Alex|2018-04-02|   Ladder|   20|         4|\n",
      "|Alex|2018-06-22|    Stool|   20|         4|\n",
      "|Alex|2018-09-26|Sandpaper|   10|         5|\n",
      "|Alex|2018-07-12|   Bucket|    5|         6|\n",
      "|Alex|2018-02-18|   Gloves|    5|         6|\n",
      "+----+----------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort purchases by descending order of price and have continuous ranking for ties.\n",
    "df.withColumn('price_rank',F.dense_rank().over(w0.orderBy(F.col('price').desc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13fd26ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+\n",
      "|name|      date|  product|price|price_rank|\n",
      "+----+----------+---------+-----+----------+\n",
      "|Alex|2018-07-12|   Bucket|    5|         1|\n",
      "|Alex|2018-02-18|   Gloves|    5|         1|\n",
      "|Alex|2018-09-26|Sandpaper|   10|         3|\n",
      "|Alex|2018-04-02|   Ladder|   20|         4|\n",
      "|Alex|2018-06-22|    Stool|   20|         4|\n",
      "|Alex|2018-03-03|  Brushes|   30|         6|\n",
      "|Alex|2018-12-09|   Vacuum|   40|         7|\n",
      "|Alex|2018-10-10|    Paint|   80|         8|\n",
      "+----+----------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort purchases by ascending order of price and have skip rankings for ties.\n",
    "df.withColumn('price_rank',F.rank().over(w0.orderBy(F.col('price').asc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115282cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+------------+\n",
      "|name|      date|  product|price|price_bucket|\n",
      "+----+----------+---------+-----+------------+\n",
      "|Alex|2018-10-10|    Paint|   80|           1|\n",
      "|Alex|2018-12-09|   Vacuum|   40|           1|\n",
      "|Alex|2018-03-03|  Brushes|   30|           2|\n",
      "|Alex|2018-04-02|   Ladder|   20|           2|\n",
      "|Alex|2018-06-22|    Stool|   20|           3|\n",
      "|Alex|2018-09-26|Sandpaper|   10|           3|\n",
      "|Alex|2018-07-12|   Bucket|    5|           4|\n",
      "|Alex|2018-02-18|   Gloves|    5|           4|\n",
      "+----+----------+---------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bucket purchases into 4 tiles (e.g. least expensive, middle tiers and most expensive purchases).\n",
    "df.withColumn('price_bucket',F.ntile(4).over(w0.orderBy(F.col('price').desc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc4f896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+-------------------+\n",
      "|name|      date|  product|price|     price_rel_rank|\n",
      "+----+----------+---------+-----+-------------------+\n",
      "|Alex|2018-10-10|    Paint|   80|                0.0|\n",
      "|Alex|2018-12-09|   Vacuum|   40|0.14285714285714285|\n",
      "|Alex|2018-03-03|  Brushes|   30| 0.2857142857142857|\n",
      "|Alex|2018-04-02|   Ladder|   20|0.42857142857142855|\n",
      "|Alex|2018-06-22|    Stool|   20|0.42857142857142855|\n",
      "|Alex|2018-09-26|Sandpaper|   10| 0.7142857142857143|\n",
      "|Alex|2018-07-12|   Bucket|    5| 0.8571428571428571|\n",
      "|Alex|2018-02-18|   Gloves|    5| 0.8571428571428571|\n",
      "+----+----------+---------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort purchases and generating a relative/percent rank to distance from max price.\n",
    "df.withColumn('price_rel_rank',F.percent_rank().over(w0.orderBy(F.col('price').desc()))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3189056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+-----------+----------------+-----------+------------+-------------+\n",
      "|name|      date|  product|price|avg_to_date|accumulating_sum|max_to_date|max_of_last2|items_to_date|\n",
      "+----+----------+---------+-----+-----------+----------------+-----------+------------+-------------+\n",
      "|Alex|2018-02-18|   Gloves|    5|        5.0|               5|          5|           5|            1|\n",
      "|Alex|2018-03-03|  Brushes|   30|       17.5|              35|         30|          30|            2|\n",
      "|Alex|2018-04-02|   Ladder|   20|      18.33|              55|         30|          30|            3|\n",
      "|Alex|2018-06-22|    Stool|   20|      18.75|              75|         30|          20|            4|\n",
      "|Alex|2018-07-12|   Bucket|    5|       16.0|              80|         30|          20|            5|\n",
      "|Alex|2018-09-26|Sandpaper|   10|       15.0|              90|         30|          10|            6|\n",
      "|Alex|2018-10-10|    Paint|   80|      24.29|             170|         80|          80|            7|\n",
      "|Alex|2018-12-09|   Vacuum|   40|      26.25|             210|         80|          80|            8|\n",
      "+----+----------+---------+-----+-----------+----------------+-----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# common calculations\n",
    "df.withColumn('avg_to_date',     F.round(F.avg('price').over(w0.orderBy(F.col('date'))),2))\\\n",
    "  .withColumn('accumulating_sum',F.sum('price').over(w0.orderBy(F.col('date'))))\\\n",
    "  .withColumn('max_to_date',     F.max('price').over(w0.orderBy(F.col('date'))))\\\n",
    "  .withColumn('max_of_last2',    F.max('price').over(w0.orderBy(F.col('date')).rowsBetween(-1,Window.currentRow)))\\\n",
    "  .withColumn('items_to_date',   F.count('*').over(w0.orderBy(F.col('date'))))\\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a39ac2",
   "metadata": {},
   "source": [
    "## Row Item Difference\n",
    "\n",
    "The two functions below, **lag** and **lead**, are probably the most abstract examples in this article and could be confusing at first. The core concept here is essentially a subtraction between some row (e.g. current) and prior or future row(s). For examples, from the table below we can say “ 13 = (2018–03–03) — (2018–02–18) “ — which is a difference of days between two dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71d153a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+-----------------------+-------------------------+\n",
      "|name|      date|  product|price|days_from_last_purchase|days_before_next_purchase|\n",
      "+----+----------+---------+-----+-----------------------+-------------------------+\n",
      "|Alex|2018-02-18|   Gloves|    5|                   null|                       13|\n",
      "|Alex|2018-03-03|  Brushes|   30|                     13|                       30|\n",
      "|Alex|2018-04-02|   Ladder|   20|                     30|                       81|\n",
      "|Alex|2018-06-22|    Stool|   20|                     81|                       20|\n",
      "|Alex|2018-07-12|   Bucket|    5|                     20|                       76|\n",
      "|Alex|2018-09-26|Sandpaper|   10|                     76|                       14|\n",
      "|Alex|2018-10-10|    Paint|   80|                     14|                       60|\n",
      "|Alex|2018-12-09|   Vacuum|   40|                     60|                     null|\n",
      "+----+----------+---------+-----+-----------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('days_from_last_purchase', F.datediff('date',F.lag('date',1).over(w0.orderBy(F.col('date')))))\\\n",
    "  .withColumn('days_before_next_purchase', F.datediff(F.lead('date',1).over(w0.orderBy(F.col('date'))),'date'))\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a109d",
   "metadata": {},
   "source": [
    "## Aggregations : Lists and Sets\n",
    "\n",
    "Collect a set of prices ever paid (no duplicates) and collect a list of items paid at a certain price (permit duplicates).\n",
    "\n",
    "I’m adding another purchase of paint to my data set in line 1 for the sake of example to generate duplicated items in lines 14 & 15 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf2f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------------+--------------------+\n",
      "|name|      date|  product|price|  items_by_price|          all_prices|\n",
      "+----+----------+---------+-----+----------------+--------------------+\n",
      "|Alex|2018-07-12|   Bucket|    5|[Bucket, Gloves]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-02-18|   Gloves|    5|[Bucket, Gloves]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-09-26|Sandpaper|   10|     [Sandpaper]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-10-10|    Paint|   80|  [Paint, Paint]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-10-11|    Paint|   80|  [Paint, Paint]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-03-03|  Brushes|   30|       [Brushes]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-04-02|   Ladder|   20| [Ladder, Stool]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-06-22|    Stool|   20| [Ladder, Stool]|[30, 5, 20, 10, 4...|\n",
      "|Alex|2018-12-09|   Vacuum|   40|        [Vacuum]|[30, 5, 20, 10, 4...|\n",
      "+----+----------+---------+-----+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newRow = spark.createDataFrame([('Alex','2018-10-11','Paint',80)])\n",
    "df2 = df.union(newRow)\n",
    "\n",
    "df2.withColumn('items_by_price', F.collect_list('product').over(w0.partitionBy('price')))\\\n",
    "   .withColumn('all_prices',     F.collect_set('price').over(w0)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1047649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------------+\n",
      "|name|Price|           items|\n",
      "+----+-----+----------------+\n",
      "|Alex|    5|[Bucket, Gloves]|\n",
      "|Alex|   10|     [Sandpaper]|\n",
      "|Alex|   80|         [Paint]|\n",
      "|Alex|   30|       [Brushes]|\n",
      "|Alex|   20| [Ladder, Stool]|\n",
      "|Alex|   40|        [Vacuum]|\n",
      "+----+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn('items', F.collect_set('product').over(w0.partitionBy('price')))\\\n",
    "   .select('name','Price','items')\\\n",
    "   .distinct()\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e398f9",
   "metadata": {},
   "source": [
    "## Time Series — Moving Average\n",
    "\n",
    "This is another slightly abstract idea along the lines of lag and lead. In this case we use the current row against a user defined range (e.g. 30 day buffer) in order to find a numerical value (e.g. mean) with the specified range.\n",
    "As an example, let’s say I want to calculate the average purchase price over the past 30 days for each single \n",
    "purchase. \n",
    "\n",
    "From the example below on line 2, 17.5 = ( 5 + 30) /2 since the two purchases were within 30 days. Also we see a 40 = 40 / 1 , because the vacuum was the only product purchased in its look back period of 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3033b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+-----+----------+----------------+------------------+\n",
      "|name|      date|  product|price| unix_time|30day_moving_avg| 45day_moving_stdv|\n",
      "+----+----------+---------+-----+----------+----------------+------------------+\n",
      "|Alex|2018-02-18|   Gloves|    5|1518930000|             5.0| 17.67766952966369|\n",
      "|Alex|2018-03-03|  Brushes|   30|1520053200|            17.5| 17.67766952966369|\n",
      "|Alex|2018-04-02|   Ladder|   20|1522641600|            25.0|7.0710678118654755|\n",
      "|Alex|2018-06-22|    Stool|   20|1529640000|            20.0|              null|\n",
      "|Alex|2018-07-12|   Bucket|    5|1531368000|            12.5|10.606601717798213|\n",
      "|Alex|2018-09-26|Sandpaper|   10|1537934400|            10.0| 49.49747468305833|\n",
      "|Alex|2018-10-10|    Paint|   80|1539144000|            45.0| 49.49747468305833|\n",
      "|Alex|2018-12-09|   Vacuum|   40|1544331600|            40.0|              null|\n",
      "+----+----------+---------+-----+----------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days = lambda i: i * 86400 # 86400 seconds in a day  \n",
    "\n",
    "df.withColumn('unix_time',F.col('date').cast('timestamp').cast('long'))\\\n",
    "  .withColumn('30day_moving_avg', F.avg('price') \\\n",
    "              .over(w0.orderBy(F.col('unix_time')) \\\n",
    "                    .rangeBetween(-days(30),0)))\\\n",
    "  .withColumn('45day_moving_stdv',F.stddev('price') \\\n",
    "              .over(w0.orderBy(F.col('unix_time')) \\\n",
    "                    .rangeBetween(-days(30),days(15))))\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb256d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
